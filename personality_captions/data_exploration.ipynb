{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib\n",
    "import shutil\n",
    "import ast\n",
    "import base64\n",
    "import numpy as np\n",
    "import torch\n",
    "from functools import lru_cache \n",
    "from assertpy import assert_that\n",
    "\n",
    "_ = csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/eugene/anaconda3/envs/frcnn/lib/python3.7/site-packages/data/personality_captions/test.json') as f:\n",
    "    orig_gt = {x['image_hash'] : x for x in json.load(f)}\n",
    "\n",
    "with open('../datasets/personality_captions/test.json') as f:\n",
    "    gt = {x['image_hash'] : x for x in json.load(f)}\n",
    "\n",
    "with open('../experiments/sequence/pred.personality_captions.test.beam5.max20.odlabels_coco_format.json') as f:\n",
    "    sequence = json.load(f)\n",
    "    \n",
    "with open('../experiments/inject/checkpoint-20-15000/pred.personality_captions.test.beam5.max20.odlabels_coco_format.json') as f:\n",
    "    inject = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    shutil.copy(f'../datasets/yfcc_images/{inject[i][\"image_id\"]}.jpg', f'../datasets/yfcc_extract/{inject[i][\"image_id\"]}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/personality_captions/test.label.tsv') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    labels = {}\n",
    "    for x in tqdm(reader):\n",
    "        eval_list = ast.literal_eval(x[1])\n",
    "        all_labels = [l['class'] for l in eval_list]\n",
    "        labels[x[0]] = all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(i):\n",
    "    image_id, seq_caption = sequence[i].values()\n",
    "    _, inj_caption = inject[i].values()\n",
    "    \n",
    "    actual_caption = gt[image_id]['comment']\n",
    "    personality = gt[image_id]['personality']\n",
    "    orig = orig_gt[image_id]['personality']\n",
    "    assert actual_caption == orig_gt[image_id]['comment']\n",
    "    \n",
    "    img = mpimg.imread(f'../datasets/yfcc_images/{image_id}.jpg')\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"ID: {image_id}, Personality: {personality} \\\n",
    "    \\n\\nLabels : {labels[image_id]}\\\n",
    "    \\n\\nGround Truth: {actual_caption} \\\n",
    "    \\nSequence: {seq_caption} \\\n",
    "    \\nInject: {inj_caption}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    difference(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captions\n",
    "\n",
    "- most images tied to only one personality and contain one caption only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalities = defaultdict(list)\n",
    "for ftype in ['train', 'val', 'test']:\n",
    "    with open(f'../datasets/personality_captions/{ftype}.json') as f:\n",
    "        for x in json.load(f):\n",
    "            personalities[x['personality']].append(x['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "personalities['Neurotic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/eugene/anaconda3/envs/frcnn/lib/python3.7/site-packages/data/personality_captions/test.json') as f:\n",
    "    orig_gt = {x['image_hash'] : x for x in json.load(f)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_gt['73a33823bb3e8ef618bf52f4b3147d'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if parlai uses caption retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_captions = set()\n",
    "for v in personalities.values():\n",
    "    all_captions.update(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = \"summer camp is so much fun!\"\n",
    "generated in all_captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirm features loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "4989"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../datasets/personality_captions/val.json') as f:\n",
    "    gt = {x['image_hash'] : x for x in json.load(f)}\n",
    "len(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4989it [00:02, 2283.35it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('../datasets/personality_captions/val.label.tsv') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    labels = {}\n",
    "    for x in tqdm(reader):\n",
    "        eval_list = ast.literal_eval(x[1])\n",
    "        all_labels = [l['class'] for l in eval_list]\n",
    "        labels[x[0]] = all_labels\n",
    "\n",
    "assert all(x in labels for x in gt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'personality': 'Irrational', 'comment': 'Is she doing a backflip twist?', 'image_hash': 'd0abfaaa84faa3729e2a76b838a317'}\n",
      "['grass', 'park', 'grass', 'shirt', 'sky', 'sky', 'shirt', 'flag', 'shorts', 'man', 'shoe', 'man', 'woman', 'grass', 'woman', 'shoe', 'woman', 'man', 'tree', 'man', 'hair', 'shorts', 'people', 'head', 'shoe', 'flag', 'hair', 'hair', 'trees', 'head', 'face', 'man', 'woman', 'shirt', 'shorts', 'pants', 'hair', 'hand', 'shoes', 'shirt', 'shirt', 'shoes']\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "image_hash = 'd0abfaaa84faa3729e2a76b838a317'\n",
    "\n",
    "print(gt[image_hash])\n",
    "print(labels[image_hash])\n",
    "print(len(labels[image_hash]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 690\n",
    "\n",
    "with open('../datasets/personality_captions/val.feature.lineidx') as f:\n",
    "    lineidx = [int(i.strip()) for i in f.readlines()]\n",
    "\n",
    "with open('../datasets/personality_captions/val.feature.tsv') as f:\n",
    "    f.seek(lineidx[idx])\n",
    "    x = f.readline().split('\\t')\n",
    "    feat_info = ast.literal_eval(x[1])\n",
    "    num_boxes = feat_info['num_boxes']\n",
    "    features = np.frombuffer(base64.b64decode(feat_info['features']), np.float32).reshape((num_boxes, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.7432358 , 0.        , ..., 0.99833333, 0.78539836,\n        0.48384783],\n       [0.00362616, 1.5246546 , 0.        , ..., 0.88631034, 0.88410103,\n        0.6500872 ],\n       [0.        , 0.6016352 , 0.        , ..., 0.9552578 , 0.8438208 ,\n        0.58567244],\n       ...,\n       [2.1922884 , 0.00713   , 0.        , ..., 0.38407785, 0.13397083,\n        0.15796061],\n       [0.77029437, 0.        , 0.        , ..., 0.42675507, 0.08198227,\n        0.1558083 ],\n       [0.00369582, 3.601428  , 0.521975  , ..., 0.8618137 , 0.21393006,\n        0.11427486]], dtype=float32)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(54348.6758)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.tensor(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "42"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare to ensure correct generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=128)\n",
    "def get_labels(old):\n",
    "    # compare labels\n",
    "    with open(old) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        od_labels = {}\n",
    "        for x in tqdm(reader):\n",
    "            eval_list = ast.literal_eval(x[1])\n",
    "            all_labels = [l['class'] for l in eval_list]\n",
    "            od_labels[x[0]] = all_labels\n",
    "    return od_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_labels(old, new):\n",
    "    od_labels = get_labels(old)\n",
    "    with open(new) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for x in tqdm(reader):\n",
    "            if x[0] in od_labels:\n",
    "                eval_list = ast.literal_eval(x[1])\n",
    "                all_labels = [l['class'] for l in eval_list]\n",
    "                assert_that(all_labels).is_equal_to(od_labels[x[0]])\n",
    "            else:\n",
    "                tqdm.write(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare features\n",
    "@lru_cache(maxsize=128)\n",
    "def get_features(old):\n",
    "    with open(old) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        gen = {}\n",
    "        for x in tqdm(reader):\n",
    "            feat_info = ast.literal_eval(x[1])\n",
    "            num_boxes = feat_info['num_boxes']\n",
    "            features = np.frombuffer(base64.b64decode(feat_info['features']), np.float32).reshape((num_boxes, -1))\n",
    "            gen[x[0]] = (features, num_boxes)\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_features(old, new):\n",
    "    gen = get_features(old)\n",
    "    with open(new) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for x in tqdm(reader):\n",
    "            if x[0] in gen:\n",
    "                feat_info = ast.literal_eval(x[1])\n",
    "                num_boxes = feat_info['num_boxes']\n",
    "                features = np.frombuffer(base64.b64decode(feat_info['features']), np.float32).reshape((num_boxes, -1))\n",
    "                \n",
    "                assert_that(num_boxes).is_equal_to(gen[x[0]][1])\n",
    "                (features == gen[x[0]][0]).all()\n",
    "            else:\n",
    "                print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare regenerated test images for pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_labels('../datasets/personality_captions/test.label.tsv', '../datasets/regen/personality_captions/labels.yfcc.tsv.0')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_features('../datasets/personality_captions/test.feature.tsv', '../datasets/regen/personality_captions/yfcc.tsv.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare coco_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare labels\n",
    "with open(\"../datasets/coco_caption/test.label.tsv\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    od_labels = {}\n",
    "    for x in tqdm(reader):\n",
    "        eval_list = ast.literal_eval(x[1])\n",
    "        all_labels = [l for l in eval_list]\n",
    "        od_labels[x[0]] = all_labels\n",
    "\n",
    "with open('../datasets/regen/coco_caption/labels.yfcc.tsv.0') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    new_labels = {}\n",
    "    for x in tqdm(reader):\n",
    "        eval_list = ast.literal_eval(x[1])\n",
    "        all_labels = [l for l in eval_list]\n",
    "        new_labels[x[0]] = all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = get_features('../datasets/coco_caption/test.feature.tsv')\n",
    "\n",
    "with open('../datasets/regen/coco_caption/yfcc.tsv.0') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    new_features = {}\n",
    "    for x in tqdm(reader):\n",
    "        feat_info = ast.literal_eval(x[1])\n",
    "        num_boxes = feat_info['num_boxes']\n",
    "        np_arr = np.frombuffer(base64.b64decode(feat_info['features']), np.float32).reshape((num_boxes, -1))\n",
    "        new_features[x[0]] = (np_arr, num_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare \n",
    "image_id = '483108'\n",
    "\n",
    "a = new_features[image_id][0]\n",
    "b = features[image_id][0]\n",
    "b = np.delete(b, (27), axis=0)\n",
    "x = abs(a-b) / (b+ np.finfo(float).eps)\n",
    "x = np.mean(x, 1)\n",
    "x = np.mean(x)\n",
    "x * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff(i):\n",
    "    a = np.asarray(new_labels[image_id][i]['rect'])\n",
    "    b = np.asarray(od_labels[image_id][i]['rect'])\n",
    "    x = abs(a-b) / (b+ np.finfo(float).eps)\n",
    "    x = np.mean(x)\n",
    "    return x\n",
    "    \n",
    "np.mean([get_diff(i) for i in range(37)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}