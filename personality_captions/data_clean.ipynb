{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "#os.chdir('../datasets/personality_captions')\n",
    "os.chdir('/home/eugene/anaconda3/envs/frcnn/lib/python3.7/site-packages/data/personality_captions')\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file):\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    return Counter(d['comment'] for d in data)\n",
    "counts = {x : load_json(f'{x}.json') for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [('[DISCONNECT]', 68), ('[RETURNED]', 28), ('What is this?', 15), ('[TIMEOUT]', 13), ('What is that?', 12), ('Where is this?', 11), ('What is going on here?', 10), ('This looks like so much fun!', 9), (\"What's going on here?\", 9), ('what is that?', 7)] \n",
      "\n",
      "val [('[DISCONNECT]', 5), ('I would hide', 2), ('THE GUY IS SUFFERING FROM DEPRESSION', 1), ('Is she doing a backflip twist?', 1), ('What did they have to do to help support cancer? Fundraisers always intrigue me', 1), ('I love the bit of motion blur in this photo, asks plenty of questions as to why this person took such an active, lovely photo.', 1), ('Sunlight filtered by sleepy clouds.', 1), ('what a wonderful map', 1), ('Why is that guy bulling the little one.', 1), (\"She's really cool and funny\", 1)] \n",
      "\n",
      "test [('[DISCONNECT]', 10), ('[RETURNED]', 3), ('[TIMEOUT]', 3), ('I do not have time for this.', 2), ('What is going on here?', 2), ('This is the life', 2), ('What even is this?', 2), ('I love the way this color makes me feel', 2), (\"I can't decide.\", 2), ('i love this country', 2)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in counts.items():\n",
    "    print(k, v.most_common(10), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning train.json, before : 186858\n",
      "after : 186749\n",
      "cleaning val.json, before : 5000\n",
      "after : 4994\n",
      "cleaning test.json, before : 10000\n",
      "after : 9984\n"
     ]
    }
   ],
   "source": [
    "# clean the captions data with [DISCONNECT], [RETURNED] and [TIMEOUT].\n",
    "def clean_captions(file):\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "    tokens = ['[DISCONNECT]', '[RETURNED]', '[TIMEOUT]']\n",
    "    print(f'cleaning {file}, before : {len(data)}')\n",
    "    \n",
    "    cleaned = [d for d in data if d['comment'] not in tokens]\n",
    "    \n",
    "    print(f'after : {len(cleaned)}')\n",
    "    with open(file, 'w') as f:\n",
    "        json.dump(cleaned, f)\n",
    "\n",
    "for x in ['train', 'val', 'test']:\n",
    "    clean_captions(f'{x}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [('What is this?', 15), ('What is that?', 12), ('Where is this?', 11), ('What is going on here?', 10), ('This looks like so much fun!', 9), (\"What's going on here?\", 9), ('what is that?', 7), ('What is he doing?', 7), ('what is this', 6), ('Is this supposed to be art?', 6)] \n",
      "\n",
      "len 1 [] \n",
      "\n",
      "val [('I would hide', 2), ('THE GUY IS SUFFERING FROM DEPRESSION', 1), ('Is she doing a backflip twist?', 1), ('What did they have to do to help support cancer? Fundraisers always intrigue me', 1), ('I love the bit of motion blur in this photo, asks plenty of questions as to why this person took such an active, lovely photo.', 1), ('Sunlight filtered by sleepy clouds.', 1), ('what a wonderful map', 1), ('Why is that guy bulling the little one.', 1), (\"She's really cool and funny\", 1), ('These people sitting at nice tables could have dressed a bit nicer, too.', 1)] \n",
      "\n",
      "len 1 [] \n",
      "\n",
      "test [('I do not have time for this.', 2), ('What is going on here?', 2), ('This is the life', 2), ('What even is this?', 2), ('I love the way this color makes me feel', 2), (\"I can't decide.\", 2), ('i love this country', 2), ('I wish I was there!', 2), (\"A little heavy on the make-up don't ya think. \", 1), ('Something about the pattern calms me', 1)] \n",
      "\n",
      "len 1 [] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "counts = {x : load_json(f'{x}.json') for x in ['train', 'val', 'test']}\n",
    "for k, v in counts.items():\n",
    "    print(k, v.most_common(10), '\\n')\n",
    "    print('len 1', [x for x in v.keys() if len(x.split(' ')) == 1], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total captions : 201727\n"
     ]
    }
   ],
   "source": [
    "print(f'total captions : {sum(sum(v.values()) for v in counts.values())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "856it [00:00, 8558.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 186749, 'val': 4994, 'test': 9984}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201230it [00:22, 8767.67it/s]\n",
      "8it [00:00, 75.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 186238, 'val': 4989, 'test': 9977}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201230it [31:24, 106.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 186238, 'val': 4989, 'test': 9977}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_json(file):\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "    return set(x['image_hash'] for x in data)\n",
    "\n",
    "    \n",
    "def split(infile, ids):\n",
    "    # merge tsv files\n",
    "    with tqdm() as pbar:\n",
    "        infile = Path(infile)\n",
    "        train_name = infile.parent / f\"train.{infile.name}\"\n",
    "        test_name = infile.parent / f\"test.{infile.name}\"\n",
    "        val_name = infile.parent / f\"val.{infile.name}\"\n",
    "        \n",
    "        counts = {k : 0 for k in ids.keys()}\n",
    "        \n",
    "        with open(train_name, 'w') as train_tsv, open(test_name, 'w') as test_tsv, open(val_name, 'w') as val_tsv, open(\"/dev/null\", 'w') as dummy:\n",
    "            \n",
    "            train_writer = csv.writer(train_tsv, delimiter = '\\t')   \n",
    "            test_writer = csv.writer(test_tsv, delimiter = '\\t')   \n",
    "            val_writer = csv.writer(val_tsv, delimiter = '\\t')   \n",
    "            \n",
    "            dummy_writer = csv.writer(dummy, delimiter = '\\t')\n",
    "            \n",
    "            \n",
    "            with open(infile) as in_tsv:\n",
    "                reader = csv.reader(in_tsv, delimiter='\\t')\n",
    "                \n",
    "                for item in reader:\n",
    "                    image_id = item[0]\n",
    "                    \n",
    "                    # check for write errors\n",
    "                    try:\n",
    "                        dummy_writer.writerow(item)\n",
    "                    except Exception as e:\n",
    "                        tqdm.write(f'write error for {image_id}, {str(e)}')\n",
    "                        continue\n",
    "                        \n",
    "                    if image_id in ids['train']:\n",
    "                        train_writer.writerow(item)\n",
    "                        counts['train'] += 1\n",
    "                    elif image_id in ids['test']:\n",
    "                        test_writer.writerow(item)\n",
    "                        counts['test'] += 1\n",
    "                    elif image_id in ids['val']:\n",
    "                        val_writer.writerow(item)\n",
    "                        counts['val'] += 1\n",
    "\n",
    "                    pbar.update(1)\n",
    "    tqdm.write(str(counts))\n",
    "ids = {x : load_json(f'{x}.json') for x in ['train', 'val', 'test']}\n",
    "tqdm.write(str({k : len(v) for k, v in ids.items()}))\n",
    "\n",
    "split('label.tsv', ids)\n",
    "split('feature.tsv', ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(feat_file, label_file):\n",
    "    def get_ids(f):\n",
    "         with open(f) as in_tsv:\n",
    "            reader = csv.reader(in_tsv, delimiter='\\t')\n",
    "            ids = {}\n",
    "            for i, x in enumerate(reader):\n",
    "                if x[0] in ids:\n",
    "                    print(f'duplicate {x[0]}')\n",
    "                ids[x[0]] = i \n",
    "            return ids\n",
    "        \n",
    "    feat_ids = get_ids(feat_file)\n",
    "    label_ids = get_ids(label_file)\n",
    "    \n",
    "    assert len(feat_ids) == len(label_ids)\n",
    "    assert feat_ids.keys() == label_ids.keys()\n",
    "    assert all(idx == label_ids[k] for k, idx in feat_ids.items())\n",
    "    print(len(label_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "186238\n",
      "val\n",
      "4989\n",
      "test\n",
      "9977\n"
     ]
    }
   ],
   "source": [
    "for x in ['train', 'val', 'test']:\n",
    "    print(x)\n",
    "    validate(f'{x}.feature.tsv',f'{x}.label.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lineidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "def generate_lineidx(filein, idxout):\n",
    "    idxout_tmp = idxout + '.tmp'\n",
    "    with open(filein, 'r') as tsvin, open(idxout_tmp,'w') as tsvout:\n",
    "        fsize = os.fstat(tsvin.fileno()).st_size\n",
    "        fpos = 0\n",
    "        while fpos!=fsize:\n",
    "            tsvout.write(str(fpos)+\"\\n\")\n",
    "            tsvin.readline()\n",
    "            fpos = tsvin.tell()\n",
    "    os.rename(idxout_tmp, idxout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "val\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "for x in ['train', 'val', 'test']:\n",
    "    print(x)\n",
    "    generate_lineidx(f'{x}.feature.tsv', f'{x}.feature.lineidx')\n",
    "    generate_lineidx(f'{x}.label.tsv', f'{x}.label.lineidx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove missing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "186238\n",
      "val\n",
      "4989\n",
      "test\n",
      "9977\n"
     ]
    }
   ],
   "source": [
    "def update_captions(label_tsv, caption_json):\n",
    "    with open(label_tsv) as in_tsv:\n",
    "        reader = csv.reader(in_tsv, delimiter='\\t')\n",
    "        label_ids = {x[0] for x in reader}\n",
    "        \n",
    "    with open(caption_json) as f:\n",
    "        captions = json.load(f)\n",
    "    \n",
    "    captions = [x for x in captions if x['image_hash'] in label_ids]\n",
    "    \n",
    "    assert len(captions) == len(label_ids)\n",
    "    \n",
    "    with open(caption_json, 'w') as f:\n",
    "        json.dump(captions, f)\n",
    "    \n",
    "    print(len(captions))\n",
    "for x in ['train', 'val', 'test']:\n",
    "    print(x)\n",
    "    update_captions(f'{x}.label.tsv', f'{x}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Personality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning train.json, before : 186238\n",
      "after : 186238\n",
      "cleaning val.json, before : 4989\n",
      "after : 4989\n",
      "cleaning test.json, before : 9977\n",
      "after : 9977\n"
     ]
    }
   ],
   "source": [
    "# remove it to one word\n",
    "personalities = set()\n",
    "def clean_personality(file):\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "    print(f'cleaning {file}, before : {len(data)}')\n",
    "    \n",
    "    cleaned = []\n",
    "    for d in data:\n",
    "        d['personality'] = d['personality'].split(' ')[0]\n",
    "        personalities.add(d['personality'])\n",
    "        cleaned.append(d)\n",
    "        \n",
    "    print(f'after : {len(cleaned)}')\n",
    "    \n",
    "    with open(file, 'w') as f:\n",
    "        json.dump(cleaned, f)\n",
    "\n",
    "for x in ['train', 'val', 'test']:\n",
    "    clean_personality(f'{x}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(x) == 1 for x in personalities)\n",
    "\n",
    "with open('personalities.txt', 'w') as f:\n",
    "    f.writelines(str(x) + '\\n' for x in personalities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create small val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/eugene/workspace/Oscar/datasets/personality_captions')\n",
    "personalities = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201204it [00:01, 110100.35it/s]\n"
     ]
    }
   ],
   "source": [
    "with tqdm() as pbar:\n",
    "    for i in ['train.json', 'val.json', 'test.json']:\n",
    "        with open(i) as f:\n",
    "            json_data = json.load(f)\n",
    "        for x in json_data:\n",
    "            personalities[x['personality']] += 1\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'Intense': 923,\n",
       "             'Adventurous': 935,\n",
       "             'Mellow': 937,\n",
       "             'Zany': 940,\n",
       "             'Narcissistic': 947,\n",
       "             'Sarcastic': 946,\n",
       "             'Artificial': 934,\n",
       "             'Eloquent': 944,\n",
       "             'Caring': 927,\n",
       "             'Appreciative': 940,\n",
       "             'Ordinary': 937,\n",
       "             'Honest': 947,\n",
       "             'Imaginative': 927,\n",
       "             'Daring': 921,\n",
       "             'Overimaginative': 945,\n",
       "             'Respectful': 937,\n",
       "             'Profound': 947,\n",
       "             'Arrogant': 933,\n",
       "             'Contemplative': 929,\n",
       "             'Glamorous': 931,\n",
       "             'Angry': 937,\n",
       "             'Contemptible': 933,\n",
       "             'Old-fashioned': 934,\n",
       "             'Witty': 940,\n",
       "             'Casual': 938,\n",
       "             'Kind': 924,\n",
       "             'Fiery': 937,\n",
       "             'Spirited': 935,\n",
       "             'Intelligent': 941,\n",
       "             'Obnoxious': 941,\n",
       "             'Cute': 944,\n",
       "             'Pretentious': 934,\n",
       "             'Aloof': 932,\n",
       "             'Crazy': 935,\n",
       "             'High-spirited': 935,\n",
       "             'Questioning': 940,\n",
       "             'Morbid': 931,\n",
       "             'Confused': 936,\n",
       "             'Irrational': 929,\n",
       "             'Impersonal': 950,\n",
       "             'Vague': 937,\n",
       "             'Rigid': 957,\n",
       "             'Boyish': 933,\n",
       "             'Wishful': 942,\n",
       "             'Humble': 932,\n",
       "             'Realistic': 940,\n",
       "             'Tough': 924,\n",
       "             'Fickle': 947,\n",
       "             'Unrealistic': 930,\n",
       "             'Unimaginative': 945,\n",
       "             'Complex': 945,\n",
       "             'Foolish': 933,\n",
       "             'Frivolous': 940,\n",
       "             'Odd': 927,\n",
       "             'Objective': 935,\n",
       "             'Energetic': 939,\n",
       "             'Grim': 936,\n",
       "             'Creative': 929,\n",
       "             'Reflective': 932,\n",
       "             'Extreme': 927,\n",
       "             'Charming': 940,\n",
       "             'Discouraging': 932,\n",
       "             'Critical': 937,\n",
       "             'Quirky': 943,\n",
       "             'Hateful': 921,\n",
       "             'Scornful': 923,\n",
       "             'Blunt': 932,\n",
       "             'Peaceful': 935,\n",
       "             'Paranoid': 936,\n",
       "             'Calm': 938,\n",
       "             'Provocative': 937,\n",
       "             'Opinionated': 935,\n",
       "             'Haughty': 929,\n",
       "             'Insightful': 927,\n",
       "             'Monstrous': 940,\n",
       "             'Relaxed': 930,\n",
       "             'Captivating': 934,\n",
       "             'Colorful': 939,\n",
       "             'Enigmatic': 939,\n",
       "             'Playful': 936,\n",
       "             'Wise': 913,\n",
       "             'Shy': 944,\n",
       "             'Sensual': 935,\n",
       "             'Sophisticated': 941,\n",
       "             'Anxious': 941,\n",
       "             'Formal': 935,\n",
       "             'Silly': 935,\n",
       "             'Boisterous': 933,\n",
       "             'Cerebral': 930,\n",
       "             'Extravagant': 925,\n",
       "             'Malicious': 941,\n",
       "             'Idealistic': 945,\n",
       "             'Conceited': 939,\n",
       "             'Observant': 947,\n",
       "             'Devious': 940,\n",
       "             'Romantic': 931,\n",
       "             'Grand': 932,\n",
       "             'Bewildered': 924,\n",
       "             'Coarse': 925,\n",
       "             'Fanciful': 925,\n",
       "             'Rational': 931,\n",
       "             'Spontaneous': 937,\n",
       "             'Obsessive': 946,\n",
       "             'Empathetic': 942,\n",
       "             'Fawning': 949,\n",
       "             'Cultured': 930,\n",
       "             'Absentminded': 932,\n",
       "             'Simple': 923,\n",
       "             'Cowardly': 922,\n",
       "             'Fun-loving': 955,\n",
       "             'Bizarre': 930,\n",
       "             'Optimistic': 946,\n",
       "             'Elegant': 943,\n",
       "             'Barbaric': 927,\n",
       "             'Confident': 945,\n",
       "             'Vivacious': 948,\n",
       "             'Logical': 933,\n",
       "             'Dull': 934,\n",
       "             'Neurotic': 936,\n",
       "             'Humorous': 927,\n",
       "             'Clever': 938,\n",
       "             'Sympathetic': 943,\n",
       "             'Meticulous': 930,\n",
       "             'Contradictory': 939,\n",
       "             'Freethinking': 947,\n",
       "             'Businesslike': 941,\n",
       "             'Abrasive': 938,\n",
       "             'Warm': 946,\n",
       "             'Stiff': 936,\n",
       "             'Miserable': 936,\n",
       "             'Attractive': 945,\n",
       "             'Destructive': 936,\n",
       "             'Patriotic': 937,\n",
       "             'Perceptive': 946,\n",
       "             'Aggressive': 941,\n",
       "             'Maternal': 920,\n",
       "             'Breezy': 935,\n",
       "             'Sentimental': 936,\n",
       "             'Vacuous': 935,\n",
       "             'Passive': 949,\n",
       "             'Offhand': 929,\n",
       "             'Envious': 938,\n",
       "             'Happy': 933,\n",
       "             'Gloomy': 952,\n",
       "             'Curious': 936,\n",
       "             'Artful': 931,\n",
       "             'Ridiculous': 938,\n",
       "             'Melancholic': 938,\n",
       "             'Cynical': 935,\n",
       "             'Escapist': 941,\n",
       "             'Cheerful': 932,\n",
       "             'Rowdy': 938,\n",
       "             'Dry': 930,\n",
       "             'Neutral': 927,\n",
       "             'Cruel': 924,\n",
       "             'Nihilistic': 935,\n",
       "             'Conservative': 946,\n",
       "             'Lazy': 932,\n",
       "             'Uncreative': 943,\n",
       "             'Mystical': 939,\n",
       "             'Compassionate': 922,\n",
       "             'Solemn': 927,\n",
       "             'Gentle': 937,\n",
       "             'Courageous': 926,\n",
       "             'Whimsical': 934,\n",
       "             'Apathetic': 943,\n",
       "             'Egocentric': 941,\n",
       "             'Articulate': 935,\n",
       "             'Tense': 926,\n",
       "             'Youthful': 933,\n",
       "             'Serious': 935,\n",
       "             'Brilliant': 944,\n",
       "             'Stoic': 937,\n",
       "             'Stupid': 945,\n",
       "             'Considerate': 923,\n",
       "             'Fearful': 935,\n",
       "             'Outrageous': 933,\n",
       "             'Irritable': 948,\n",
       "             'Skeptical': 944,\n",
       "             'Resentful': 944,\n",
       "             'Excitable': 934,\n",
       "             'Erratic': 938,\n",
       "             'Passionate': 938,\n",
       "             'Pompous': 933,\n",
       "             'Fatalistic': 940,\n",
       "             'Knowledgeable': 940,\n",
       "             'Assertive': 941,\n",
       "             'Cold': 919,\n",
       "             'Dramatic': 944,\n",
       "             'Deep': 929,\n",
       "             'Exciting': 929,\n",
       "             'Suave': 939,\n",
       "             'Sweet': 939,\n",
       "             'Sensitive': 941,\n",
       "             'Stylish': 929,\n",
       "             'Fanatical': 942,\n",
       "             'Childish': 953,\n",
       "             'Open': 939,\n",
       "             'Argumentative': 931,\n",
       "             'Frightening': 936,\n",
       "             'Hostile': 940,\n",
       "             'Rustic': 945,\n",
       "             'Extraordinary': 932,\n",
       "             'Practical': 917,\n",
       "             'Money-minded': 944,\n",
       "             'Enthusiastic': 927,\n",
       "             'Emotional': 926,\n",
       "             'Earnest': 906,\n",
       "             'Scholarly': 932,\n",
       "             'Moody': 933,\n",
       "             'Bland': 938,\n",
       "             'Airy': 941,\n",
       "             'Disturbing': 931,\n",
       "             'Amusing': 948,\n",
       "             'Dreamy': 920,\n",
       "             'Crude': 4})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abrasive\n",
      "Absentminded\n",
      "Adventurous\n",
      "Aggressive\n",
      "Airy\n",
      "Aloof\n",
      "Amusing\n",
      "Angry\n",
      "Anxious\n",
      "Apathetic\n",
      "Appreciative\n",
      "Argumentative\n",
      "Arrogant\n",
      "Artful\n",
      "Articulate\n",
      "Artificial\n",
      "Assertive\n",
      "Attractive\n",
      "Barbaric\n",
      "Bewildered\n",
      "Bizarre\n",
      "Bland\n",
      "Blunt\n",
      "Boisterous\n",
      "Boyish\n",
      "Breezy\n",
      "Brilliant\n",
      "Businesslike\n",
      "Calm\n",
      "Captivating\n",
      "Caring\n",
      "Casual\n",
      "Cerebral\n",
      "Charming\n",
      "Cheerful\n",
      "Childish\n",
      "Clever\n",
      "Coarse\n",
      "Cold\n",
      "Colorful\n",
      "Compassionate\n",
      "Complex\n",
      "Conceited\n",
      "Confident\n",
      "Confused\n",
      "Conservative\n",
      "Considerate\n",
      "Contemplative\n",
      "Contemptible\n",
      "Contradictory\n",
      "Courageous\n",
      "Cowardly\n",
      "Crazy\n",
      "Creative\n",
      "Critical\n",
      "Crude\n",
      "Cruel\n",
      "Cultured\n",
      "Curious\n",
      "Cute\n",
      "Cynical\n",
      "Daring\n",
      "Deep\n",
      "Destructive\n",
      "Devious\n",
      "Discouraging\n",
      "Disturbing\n",
      "Dramatic\n",
      "Dreamy\n",
      "Dry\n",
      "Dull\n",
      "Earnest\n",
      "Egocentric\n",
      "Elegant\n",
      "Eloquent\n",
      "Emotional\n",
      "Empathetic\n",
      "Energetic\n",
      "Enigmatic\n",
      "Enthusiastic\n",
      "Envious\n",
      "Erratic\n",
      "Escapist\n",
      "Excitable\n",
      "Exciting\n",
      "Extraordinary\n",
      "Extravagant\n",
      "Extreme\n",
      "Fanatical\n",
      "Fanciful\n",
      "Fatalistic\n",
      "Fawning\n",
      "Fearful\n",
      "Fickle\n",
      "Fiery\n",
      "Foolish\n",
      "Formal\n",
      "Freethinking\n",
      "Frightening\n",
      "Frivolous\n",
      "Fun-loving\n",
      "Gentle\n",
      "Glamorous\n",
      "Gloomy\n",
      "Grand\n",
      "Grim\n",
      "Happy\n",
      "Hateful\n",
      "Haughty\n",
      "High-spirited\n",
      "Honest\n",
      "Hostile\n",
      "Humble\n",
      "Humorous\n",
      "Idealistic\n",
      "Imaginative\n",
      "Impersonal\n",
      "Insightful\n",
      "Intelligent\n",
      "Intense\n",
      "Irrational\n",
      "Irritable\n",
      "Kind\n",
      "Knowledgeable\n",
      "Lazy\n",
      "Logical\n",
      "Malicious\n",
      "Maternal\n",
      "Melancholic\n",
      "Mellow\n",
      "Meticulous\n",
      "Miserable\n",
      "Money-minded\n",
      "Monstrous\n",
      "Moody\n",
      "Morbid\n",
      "Mystical\n",
      "Narcissistic\n",
      "Neurotic\n",
      "Neutral\n",
      "Nihilistic\n",
      "Objective\n",
      "Obnoxious\n",
      "Observant\n",
      "Obsessive\n",
      "Odd\n",
      "Offhand\n",
      "Old-fashioned\n",
      "Open\n",
      "Opinionated\n",
      "Optimistic\n",
      "Ordinary\n",
      "Outrageous\n",
      "Overimaginative\n",
      "Paranoid\n",
      "Passionate\n",
      "Passive\n",
      "Patriotic\n",
      "Peaceful\n",
      "Perceptive\n",
      "Playful\n",
      "Pompous\n",
      "Practical\n",
      "Pretentious\n",
      "Profound\n",
      "Provocative\n",
      "Questioning\n",
      "Quirky\n",
      "Rational\n",
      "Realistic\n",
      "Reflective\n",
      "Relaxed\n",
      "Resentful\n",
      "Respectful\n",
      "Ridiculous\n",
      "Rigid\n",
      "Romantic\n",
      "Rowdy\n",
      "Rustic\n",
      "Sarcastic\n",
      "Scholarly\n",
      "Scornful\n",
      "Sensitive\n",
      "Sensual\n",
      "Sentimental\n",
      "Serious\n",
      "Shy\n",
      "Silly\n",
      "Simple\n",
      "Skeptical\n",
      "Solemn\n",
      "Sophisticated\n",
      "Spirited\n",
      "Spontaneous\n",
      "Stiff\n",
      "Stoic\n",
      "Stupid\n",
      "Stylish\n",
      "Suave\n",
      "Sweet\n",
      "Sympathetic\n",
      "Tense\n",
      "Tough\n",
      "Uncreative\n",
      "Unimaginative\n",
      "Unrealistic\n",
      "Vacuous\n",
      "Vague\n",
      "Vivacious\n",
      "Warm\n",
      "Whimsical\n",
      "Wise\n",
      "Wishful\n",
      "Witty\n",
      "Youthful\n",
      "Zany\n"
     ]
    }
   ],
   "source": [
    "for x in sorted(personalities.keys()): \n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201858it [00:03, 51903.76it/s]\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/eugene/anaconda3/envs/frcnn/lib/python3.7/site-packages/data/personality_captions')\n",
    "personalities_full = set()\n",
    "with tqdm() as pbar:\n",
    "    for i in ['train.json', 'val.json', 'test.json']:\n",
    "        with open(i) as f:\n",
    "            json_data = json.load(f)\n",
    "        for x in json_data:\n",
    "            personalities_full.add(x['personality'])\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalities_full = set(x.split(' ')[0] for x in personalities_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abrasive',\n",
       " 'Absentminded',\n",
       " 'Adventurous',\n",
       " 'Aggressive',\n",
       " 'Airy',\n",
       " 'Aloof',\n",
       " 'Amusing',\n",
       " 'Angry',\n",
       " 'Anxious',\n",
       " 'Apathetic',\n",
       " 'Appreciative',\n",
       " 'Argumentative',\n",
       " 'Arrogant',\n",
       " 'Artful',\n",
       " 'Articulate',\n",
       " 'Artificial',\n",
       " 'Assertive',\n",
       " 'Attractive',\n",
       " 'Barbaric',\n",
       " 'Bewildered',\n",
       " 'Bizarre',\n",
       " 'Bland',\n",
       " 'Blunt',\n",
       " 'Boisterous',\n",
       " 'Boyish',\n",
       " 'Breezy',\n",
       " 'Brilliant',\n",
       " 'Businesslike',\n",
       " 'Calm',\n",
       " 'Captivating',\n",
       " 'Caring',\n",
       " 'Casual',\n",
       " 'Cerebral',\n",
       " 'Charming',\n",
       " 'Cheerful',\n",
       " 'Childish',\n",
       " 'Clever',\n",
       " 'Coarse',\n",
       " 'Cold',\n",
       " 'Colorful',\n",
       " 'Compassionate',\n",
       " 'Complex',\n",
       " 'Conceited',\n",
       " 'Confident',\n",
       " 'Confused',\n",
       " 'Conservative',\n",
       " 'Considerate',\n",
       " 'Contemplative',\n",
       " 'Contemptible',\n",
       " 'Contradictory',\n",
       " 'Courageous',\n",
       " 'Cowardly',\n",
       " 'Crazy',\n",
       " 'Creative',\n",
       " 'Critical',\n",
       " 'Crude',\n",
       " 'Cruel',\n",
       " 'Cultured',\n",
       " 'Curious',\n",
       " 'Cute',\n",
       " 'Cynical',\n",
       " 'Daring',\n",
       " 'Deep',\n",
       " 'Destructive',\n",
       " 'Devious',\n",
       " 'Discouraging',\n",
       " 'Disturbing',\n",
       " 'Dramatic',\n",
       " 'Dreamy',\n",
       " 'Dry',\n",
       " 'Dull',\n",
       " 'Earnest',\n",
       " 'Egocentric',\n",
       " 'Elegant',\n",
       " 'Eloquent',\n",
       " 'Emotional',\n",
       " 'Empathetic',\n",
       " 'Energetic',\n",
       " 'Enigmatic',\n",
       " 'Enthusiastic',\n",
       " 'Envious',\n",
       " 'Erratic',\n",
       " 'Escapist',\n",
       " 'Excitable',\n",
       " 'Exciting',\n",
       " 'Extraordinary',\n",
       " 'Extravagant',\n",
       " 'Extreme',\n",
       " 'Fanatical',\n",
       " 'Fanciful',\n",
       " 'Fatalistic',\n",
       " 'Fawning',\n",
       " 'Fearful',\n",
       " 'Fickle',\n",
       " 'Fiery',\n",
       " 'Foolish',\n",
       " 'Formal',\n",
       " 'Freethinking',\n",
       " 'Frightening',\n",
       " 'Frivolous',\n",
       " 'Fun-loving',\n",
       " 'Gentle',\n",
       " 'Glamorous',\n",
       " 'Gloomy',\n",
       " 'Grand',\n",
       " 'Grim',\n",
       " 'Happy',\n",
       " 'Hateful',\n",
       " 'Haughty',\n",
       " 'High-spirited',\n",
       " 'Honest',\n",
       " 'Hostile',\n",
       " 'Humble',\n",
       " 'Humorous',\n",
       " 'Idealistic',\n",
       " 'Imaginative',\n",
       " 'Impersonal',\n",
       " 'Insightful',\n",
       " 'Intelligent',\n",
       " 'Intense',\n",
       " 'Irrational',\n",
       " 'Irritable',\n",
       " 'Kind',\n",
       " 'Knowledgeable',\n",
       " 'Lazy',\n",
       " 'Logical',\n",
       " 'Malicious',\n",
       " 'Maternal',\n",
       " 'Melancholic',\n",
       " 'Mellow',\n",
       " 'Meticulous',\n",
       " 'Miserable',\n",
       " 'Money-minded',\n",
       " 'Monstrous',\n",
       " 'Moody',\n",
       " 'Morbid',\n",
       " 'Mystical',\n",
       " 'Narcissistic',\n",
       " 'Neurotic',\n",
       " 'Neutral',\n",
       " 'Nihilistic',\n",
       " 'Objective',\n",
       " 'Obnoxious',\n",
       " 'Observant',\n",
       " 'Obsessive',\n",
       " 'Odd',\n",
       " 'Offhand',\n",
       " 'Old-fashioned',\n",
       " 'Open',\n",
       " 'Opinionated',\n",
       " 'Optimistic',\n",
       " 'Ordinary',\n",
       " 'Outrageous',\n",
       " 'Overimaginative',\n",
       " 'Paranoid',\n",
       " 'Passionate',\n",
       " 'Passive',\n",
       " 'Patriotic',\n",
       " 'Peaceful',\n",
       " 'Perceptive',\n",
       " 'Playful',\n",
       " 'Pompous',\n",
       " 'Practical',\n",
       " 'Pretentious',\n",
       " 'Profound',\n",
       " 'Provocative',\n",
       " 'Questioning',\n",
       " 'Quirky',\n",
       " 'Rational',\n",
       " 'Realistic',\n",
       " 'Reflective',\n",
       " 'Relaxed',\n",
       " 'Resentful',\n",
       " 'Respectful',\n",
       " 'Ridiculous',\n",
       " 'Rigid',\n",
       " 'Romantic',\n",
       " 'Rowdy',\n",
       " 'Rustic',\n",
       " 'Sarcastic',\n",
       " 'Scholarly',\n",
       " 'Scornful',\n",
       " 'Sensitive',\n",
       " 'Sensual',\n",
       " 'Sentimental',\n",
       " 'Serious',\n",
       " 'Shy',\n",
       " 'Silly',\n",
       " 'Simple',\n",
       " 'Skeptical',\n",
       " 'Solemn',\n",
       " 'Sophisticated',\n",
       " 'Spirited',\n",
       " 'Spontaneous',\n",
       " 'Stiff',\n",
       " 'Stoic',\n",
       " 'Stupid',\n",
       " 'Stylish',\n",
       " 'Suave',\n",
       " 'Sweet',\n",
       " 'Sympathetic',\n",
       " 'Tense',\n",
       " 'Tough',\n",
       " 'Uncreative',\n",
       " 'Unimaginative',\n",
       " 'Unrealistic',\n",
       " 'Vacuous',\n",
       " 'Vague',\n",
       " 'Vivacious',\n",
       " 'Warm',\n",
       " 'Whimsical',\n",
       " 'Wise',\n",
       " 'Wishful',\n",
       " 'Witty',\n",
       " 'Youthful',\n",
       " 'Zany'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personalities_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(personalities_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
