{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "import ast\n",
    "\n",
    "os.chdir('../datasets/personality_captions')\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_json(file):\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    return Counter(d['comment'] for d in data)\n",
    "counts = {x : load_json(f'{x}.json') for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [('[DISCONNECT]', 68), ('[RETURNED]', 28), ('What is this?', 15), ('[TIMEOUT]', 13), ('What is that?', 12), ('Where is this?', 11), ('What is going on here?', 10), ('This looks like so much fun!', 9), (\"What's going on here?\", 9), ('what is that?', 7)] \n",
      "\n",
      "val [('[DISCONNECT]', 5), ('I would hide', 2), ('THE GUY IS SUFFERING FROM DEPRESSION', 1), ('Is she doing a backflip twist?', 1), ('What did they have to do to help support cancer? Fundraisers always intrigue me', 1), ('I love the bit of motion blur in this photo, asks plenty of questions as to why this person took such an active, lovely photo.', 1), ('Sunlight filtered by sleepy clouds.', 1), ('what a wonderful map', 1), ('Why is that guy bulling the little one.', 1), (\"She's really cool and funny\", 1)] \n",
      "\n",
      "test [('[DISCONNECT]', 10), ('[RETURNED]', 3), ('[TIMEOUT]', 3), ('I do not have time for this.', 2), ('What is going on here?', 2), ('This is the life', 2), ('What even is this?', 2), ('I love the way this color makes me feel', 2), (\"I can't decide.\", 2), ('i love this country', 2)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in counts.items():\n",
    "    print(k, v.most_common(10), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning train.json, before : 186858\n",
      "after : 186749\n",
      "cleaning val.json, before : 5000\n",
      "after : 4994\n",
      "cleaning test.json, before : 10000\n",
      "after : 9984\n"
     ]
    }
   ],
   "source": [
    "# clean the captions data with [DISCONNECT], [RETURNED] and [TIMEOUT].\n",
    "def clean_captions(file):\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "    tokens = ['[DISCONNECT]', '[RETURNED]', '[TIMEOUT]']\n",
    "    print(f'cleaning {file}, before : {len(data)}')\n",
    "    \n",
    "    cleaned = [d for d in data if d['comment'] not in tokens]\n",
    "    \n",
    "    print(f'after : {len(cleaned)}')\n",
    "    with open(file, 'w') as f:\n",
    "        json.dump(cleaned, f)\n",
    "\n",
    "for x in ['train', 'val', 'test']:\n",
    "    clean_captions(f'{x}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [('What is this?', 15), ('What is that?', 12), ('Where is this?', 11), ('What is going on here?', 10), ('This looks like so much fun!', 9), (\"What's going on here?\", 9), ('what is that?', 7), ('What is he doing?', 7), ('what is this', 6), ('Is this supposed to be art?', 6)] \n",
      "\n",
      "len 1 [] \n",
      "\n",
      "val [('I would hide', 2), ('THE GUY IS SUFFERING FROM DEPRESSION', 1), ('Is she doing a backflip twist?', 1), ('What did they have to do to help support cancer? Fundraisers always intrigue me', 1), ('I love the bit of motion blur in this photo, asks plenty of questions as to why this person took such an active, lovely photo.', 1), ('Sunlight filtered by sleepy clouds.', 1), ('what a wonderful map', 1), ('Why is that guy bulling the little one.', 1), (\"She's really cool and funny\", 1), ('These people sitting at nice tables could have dressed a bit nicer, too.', 1)] \n",
      "\n",
      "len 1 [] \n",
      "\n",
      "test [('I do not have time for this.', 2), ('What is going on here?', 2), ('This is the life', 2), ('What even is this?', 2), ('I love the way this color makes me feel', 2), (\"I can't decide.\", 2), ('i love this country', 2), ('I wish I was there!', 2), (\"A little heavy on the make-up don't ya think. \", 1), ('Something about the pattern calms me', 1)] \n",
      "\n",
      "len 1 [] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "counts = {x : load_json(f'{x}.json') for x in ['train', 'val', 'test']}\n",
    "for k, v in counts.items():\n",
    "    print(k, v.most_common(10), '\\n')\n",
    "    print('len 1', [x for x in v.keys() if len(x.split(' ')) == 1], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total captions : 201727\n"
     ]
    }
   ],
   "source": [
    "print(f'total captions : {sum(sum(v.values()) for v in counts.values())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "856it [00:00, 8558.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 186749, 'val': 4994, 'test': 9984}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201230it [00:22, 8767.67it/s]\n",
      "8it [00:00, 75.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 186238, 'val': 4989, 'test': 9977}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201230it [31:24, 106.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 186238, 'val': 4989, 'test': 9977}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_json(file):\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "    return set(x['image_hash'] for x in data)\n",
    "\n",
    "    \n",
    "def split(infile, ids):\n",
    "    # merge tsv files\n",
    "    with tqdm() as pbar:\n",
    "        infile = Path(infile)\n",
    "        train_name = infile.parent / f\"train.{infile.name}\"\n",
    "        test_name = infile.parent / f\"test.{infile.name}\"\n",
    "        val_name = infile.parent / f\"val.{infile.name}\"\n",
    "        \n",
    "        counts = {k : 0 for k in ids.keys()}\n",
    "        \n",
    "        with open(train_name, 'w') as train_tsv, open(test_name, 'w') as test_tsv, open(val_name, 'w') as val_tsv, open(\"/dev/null\", 'w') as dummy:\n",
    "            \n",
    "            train_writer = csv.writer(train_tsv, delimiter = '\\t')   \n",
    "            test_writer = csv.writer(test_tsv, delimiter = '\\t')   \n",
    "            val_writer = csv.writer(val_tsv, delimiter = '\\t')   \n",
    "            \n",
    "            dummy_writer = csv.writer(dummy, delimiter = '\\t')\n",
    "            \n",
    "            \n",
    "            with open(infile) as in_tsv:\n",
    "                reader = csv.reader(in_tsv, delimiter='\\t')\n",
    "                \n",
    "                for item in reader:\n",
    "                    image_id = item[0]\n",
    "                    \n",
    "                    # check for write errors\n",
    "                    try:\n",
    "                        dummy_writer.writerow(item)\n",
    "                    except Exception as e:\n",
    "                        tqdm.write(f'write error for {image_id}, {str(e)}')\n",
    "                        continue\n",
    "                        \n",
    "                    if image_id in ids['train']:\n",
    "                        train_writer.writerow(item)\n",
    "                        counts['train'] += 1\n",
    "                    elif image_id in ids['test']:\n",
    "                        test_writer.writerow(item)\n",
    "                        counts['test'] += 1\n",
    "                    elif image_id in ids['val']:\n",
    "                        val_writer.writerow(item)\n",
    "                        counts['val'] += 1\n",
    "\n",
    "                    pbar.update(1)\n",
    "    tqdm.write(str(counts))\n",
    "ids = {x : load_json(f'{x}.json') for x in ['train', 'val', 'test']}\n",
    "tqdm.write(str({k : len(v) for k, v in ids.items()}))\n",
    "\n",
    "split('label.tsv', ids)\n",
    "split('feature.tsv', ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def validate(feat_file, label_file):\n",
    "    def get_ids(f):\n",
    "         with open(f) as in_tsv:\n",
    "            reader = csv.reader(in_tsv, delimiter='\\t')\n",
    "            ids = {}\n",
    "            for i, x in enumerate(reader):\n",
    "                if x[0] in ids:\n",
    "                    print(f'duplicate {x[0]}')\n",
    "                ids[x[0]] = i \n",
    "            return ids\n",
    "        \n",
    "    feat_ids = get_ids(feat_file)\n",
    "    label_ids = get_ids(label_file)\n",
    "    \n",
    "    assert len(feat_ids) == len(label_ids)\n",
    "    assert feat_ids.keys() == label_ids.keys()\n",
    "    assert all(idx == label_ids[k] for k, idx in feat_ids.items())\n",
    "    print(len(label_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "186238\n",
      "val\n",
      "4989\n",
      "test\n",
      "9977\n"
     ]
    }
   ],
   "source": [
    "for x in ['train', 'val', 'test']:\n",
    "    print(x)\n",
    "    validate(f'{x}.feature.tsv',f'{x}.label.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Lineidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "def generate_lineidx(filein, idxout):\n",
    "    idxout_tmp = idxout + '.tmp'\n",
    "    with open(filein, 'r') as tsvin, open(idxout_tmp,'w') as tsvout:\n",
    "        fsize = os.fstat(tsvin.fileno()).st_size\n",
    "        fpos = 0\n",
    "        while fpos!=fsize:\n",
    "            tsvout.write(str(fpos)+\"\\n\")\n",
    "            tsvin.readline()\n",
    "            fpos = tsvin.tell()\n",
    "    os.rename(idxout_tmp, idxout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "val\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "for x in ['train', 'val', 'test']:\n",
    "    print(x)\n",
    "    #generate_lineidx(f'{x}.feature.tsv', f'{x}.feature.lineidx')\n",
    "    generate_lineidx(f'{x}.label.tsv', f'{x}.label.lineidx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove missing labels from captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "186238\n",
      "val\n",
      "4989\n",
      "test\n",
      "9977\n"
     ]
    }
   ],
   "source": [
    "def update_captions(label_tsv, caption_json):\n",
    "    with open(label_tsv) as in_tsv:\n",
    "        reader = csv.reader(in_tsv, delimiter='\\t')\n",
    "        label_ids = {x[0] for x in reader}\n",
    "        \n",
    "    with open(caption_json) as f:\n",
    "        captions = json.load(f)\n",
    "    \n",
    "    captions = [x for x in captions if x['image_hash'] in label_ids]\n",
    "    \n",
    "    assert len(captions) == len(label_ids)\n",
    "    \n",
    "    with open(caption_json, 'w') as f:\n",
    "        json.dump(captions, f)\n",
    "    \n",
    "    print(len(captions))\n",
    "for x in ['train', 'val', 'test']:\n",
    "    print(x)\n",
    "    update_captions(f'{x}.label.tsv', f'{x}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update personality to single word form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning train.json, before : 186238\n",
      "after : 186238\n",
      "cleaning val.json, before : 4989\n",
      "after : 4989\n",
      "cleaning test.json, before : 9977\n",
      "after : 9977\n"
     ]
    }
   ],
   "source": [
    "# remove it to one word\n",
    "personalities = set()\n",
    "def clean_personality(file):\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "    print(f'cleaning {file}, before : {len(data)}')\n",
    "    \n",
    "    cleaned = []\n",
    "    for d in data:\n",
    "        d['personality'] = d['personality'].split(' ')[0]\n",
    "        personalities.add(d['personality'])\n",
    "        cleaned.append(d)\n",
    "        \n",
    "    print(f'after : {len(cleaned)}')\n",
    "    \n",
    "    with open(file, 'w') as f:\n",
    "        json.dump(cleaned, f)\n",
    "\n",
    "for x in ['train', 'val', 'test']:\n",
    "    clean_personality(f'{x}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert(len(x) == 1 for x in personalities)\n",
    "\n",
    "with open('personalities.txt', 'w') as f:\n",
    "    f.writelines(str(x) + '\\n' for x in personalities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean labels tsv to correct format for dictionary parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sed -i \"s/{'conf'/{\\\"conf\\\"/g\" *.label.tsv\n",
    "!sed -i \"s/'class': '/\\\"class\\\": \\\"/g\" *.label.tsv\n",
    "!sed -i \"s/', 'rect'/\\\", \\\"rect\\\"/g\" *.label.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sed -i 's/\"\\[/\\[/g' train.label.tsv\n",
    "!sed -i 's/\\]\"/\\]/g' train.label.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sed -i 's/\"\"/\"/g' train.label.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "229it [00:00, 1052.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "186238it [02:02, 1524.11it/s]\n",
      "453it [00:00, 2139.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4989it [00:02, 2268.65it/s]\n",
      "251it [00:00, 2501.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9977it [00:04, 2233.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for x in ['train', 'val', 'test']:\n",
    "    print(x)\n",
    "    with open(f'{x}.label.tsv') as in_tsv:\n",
    "        reader = csv.reader(in_tsv, delimiter='\\t')\n",
    "        for x in tqdm(reader):\n",
    "            parse = ast.literal_eval(x[1])\n",
    "            for x in parse:\n",
    "                assert 'class' in x\n",
    "                assert 'conf' in x\n",
    "                assert 'rect' in x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert JSON to COCO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../coco_caption/test_caption_coco_format.json') as f:\n",
    "    items = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': '179765', 'caption': 'A black Honda motorcycle parked in front of a garage.', 'id': 0}\n",
      "{'id': '179765', 'file_name': '179765'}\n",
      "captions\n",
      "dummy\n",
      "dummy\n"
     ]
    }
   ],
   "source": [
    "items.keys()\n",
    "print(items['annotations'][0])\n",
    "print(items['images'][0])\n",
    "print(items['type'])\n",
    "print(items['info'])\n",
    "print(items['licenses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('./val.json') as f:\n",
    "    items = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'personality': 'Stoic',\n",
       " 'comment': 'THE GUY IS SUFFERING FROM DEPRESSION',\n",
       " 'candidates': ['The forest is youthful',\n",
       "  \"In a crowd of people like this it's inspiring that no one is looking at their cell phones. Everyone is talking about making connections. How beautiful.\",\n",
       "  \"there's going to be a typhoon\",\n",
       "  'what is this? it looks fake',\n",
       "  'My life is full of interesting people. ',\n",
       "  'This sky is so beautiful! I wish I was there.',\n",
       "  'Oh my goodness that view is like the prettiest landscape I have ever seen!',\n",
       "  'The future is now',\n",
       "  'I wish I could dress up like that',\n",
       "  'I am so glad I am apart of this organization.',\n",
       "  'id be scared of falling in there',\n",
       "  'Looks apocalyptic, I bet that light is the sun exploding to destroy us all.',\n",
       "  'Ah, circle lights and curved buildings, how so not original',\n",
       "  \"I don't understand what you're trying to convey in this picture?  The background is nothing and you look surprised or perhaps asleep.\",\n",
       "  \"Let's party people.\",\n",
       "  'I would totally do my under water basket weaving out on a place like this.',\n",
       "  'Are those Easter peeps hanging down from the ceiling?',\n",
       "  'I bet they got first place',\n",
       "  'Father and cute son',\n",
       "  'I need to light 5 candles like this every day for 6 months at 9 oclock',\n",
       "  'What an interesting and fascinating place!',\n",
       "  'Absolutely beautiful view, it would take forever to reach the top of the hill',\n",
       "  'lame, just water',\n",
       "  'Just a man and his wife having a good, wholesome time, nothing beats it!',\n",
       "  'The two are an omnious pair',\n",
       "  'what a beautiful house!! I would love to play in this garden!!',\n",
       "  'They are scared to finish the job?',\n",
       "  'what could they possibly be doing',\n",
       "  'This family looks very old fashioned.',\n",
       "  'I could be half naked there and I think I could get away with it.  ',\n",
       "  'I have really bad allergies, I will not be going here.',\n",
       "  'yeah sure i like lizards',\n",
       "  \"I've wanted one of these since I was a child.\",\n",
       "  'I wonder how fast they can skate.',\n",
       "  \"This picture of a girl doesn't make me feel much of anything.\",\n",
       "  'What a super clever meme!',\n",
       "  'That is so freaking in right now.',\n",
       "  'I hope they all are having fun I know I am',\n",
       "  'Easy going afternoon I think.',\n",
       "  'a Chinese writing',\n",
       "  \"Those all look like they're thornless.\",\n",
       "  \"I hope I don't have to take a photo next\",\n",
       "  '.Them For Good But Know Who Doing Person This Is What',\n",
       "  'Laptops are so nice for Skyping with people you miss.',\n",
       "  \"That's a waterfall, a big one that is\",\n",
       "  'What a nice spot for a picnic and stroll !',\n",
       "  'WHAT A CUTE LITTLE GIRL',\n",
       "  'Airplanes on the tarmac.',\n",
       "  'A colourful line up of performers!',\n",
       "  'He seems to be contemplating life and all the mysteries it entails.',\n",
       "  'The sun is still to bright',\n",
       "  'cute little critters',\n",
       "  'she looks like a fun person',\n",
       "  'The bird is amazing, I love the way the wings make a beautiful line!',\n",
       "  'This kid will be graduating college in about 22 years.',\n",
       "  'I feel at peace here.',\n",
       "  'the fellow in front of us was driving so slowly that I crossed the double line to pass him',\n",
       "  ' I am so jacked, this guy cannot stop me.',\n",
       "  'THIS BOY LOOKS THE SAME IN BOTH PICTURES BUT IS A TERRIBLE SERIAL KILLER.',\n",
       "  \"Weird how by the time we've all seen this photo, someone in the frame has probably received terrible news.\",\n",
       "  \"STANDBY AND DON'T CALL ME SHIRLEY.  \",\n",
       "  'to the left you will see more',\n",
       "  'This is very religious, and very interesting.',\n",
       "  \"I can't wait to get out of here\",\n",
       "  'Ah, I see. This is a certain type of species that can only grow in these conditions.',\n",
       "  'Look at the awesome face this tower is making! Heheehehe.',\n",
       "  'What exactly is his job?',\n",
       "  \"Those guys look prepared for anything so I don't have to be.\",\n",
       "  'Friendship makes life wonderful.',\n",
       "  'Oh gosh, I love the Steelers so much!',\n",
       "  \"Sometimes, I get angry that I don't get to live in a nice place like this.\",\n",
       "  \"There are so many people! I just don't see how anyone could enjoy themselves there. \",\n",
       "  'I like his hair, it suits him.',\n",
       "  \"I'd like to fill up that tub and get in it.  I'd let my worries drain with the water when done.\",\n",
       "  'I would like to argue with this young man until we could see the sunrise.',\n",
       "  'The concrete is breaking apart quickly.',\n",
       "  \"Cloudy ward evenings in natures' golden hue.\",\n",
       "  'This looks like basketball',\n",
       "  'I could sing better than this lady.',\n",
       "  'Wow, I would LOVE to climb that tree! How great that would be!',\n",
       "  'She can twerk',\n",
       "  'This looks like such a wonderful river! I wish I could be swimming there!',\n",
       "  'I would be so grateful to see this view.',\n",
       "  'It was so manly',\n",
       "  \"Why aren't they smiling?\",\n",
       "  'So much fun! Love the hair. You all are so creative!',\n",
       "  'How vulnerable he looks ',\n",
       "  'This door looks like walking up to the gates of Beauty and the beast. I bet the beast lives here.',\n",
       "  \"what is he looking at?I don't get it.\",\n",
       "  \"I guess it's ok, the sizes could have been more uniform.\",\n",
       "  \"I really don't care about the history of that.\",\n",
       "  'Its coat would make the tiniest rug.',\n",
       "  \"It's a road. Drive!\",\n",
       "  'On such a small street, it seems like the occasional hit and run occurs far too often.',\n",
       "  'I love how the sun peeks through the gray sky just enough to cast shadows that give off a calm peaceful feeling.',\n",
       "  \"The Variegated Solomon's-Seal is species native to Europe and Asia.\",\n",
       "  'How long did it take to build this place?!',\n",
       "  'THE GUY IS SUFFERING FROM DEPRESSION',\n",
       "  'She is out for a run, for the track team, working muscles to reach the final point.',\n",
       "  'I wonder how many treasure chests are buried in that forest?'],\n",
       " 'image_hash': 'fbb6235f465efc58fcd509cf787c450'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_to_coco_format(x):\n",
    "    with open(f'{x}.json') as f:\n",
    "        captions = json.load(f)\n",
    "    \n",
    "    coco_format = {\n",
    "        'annotations' : [],\n",
    "        'images' : [],\n",
    "        'type' : 'captions',\n",
    "        'info' : 'dummy',\n",
    "        'licenses' : 'dummy'\n",
    "    }\n",
    "    \n",
    "    for i, cap in enumerate(captions):\n",
    "        coco_cap = {\n",
    "            'image_id' : cap['image_hash'], \n",
    "            'caption' : cap['comment'], \n",
    "            'id' : i \n",
    "        }\n",
    "        image_pair = {\n",
    "            'id' : cap['image_hash'],\n",
    "            'file_name' : cap['image_hash']\n",
    "        }\n",
    "        \n",
    "        coco_format['annotations'].append(coco_cap)\n",
    "        coco_format['images'].append(image_pair)\n",
    "        \n",
    "    with open(f'{x}_caption_coco_format.json', 'w') as f:\n",
    "        json.dump(coco_format, f)\n",
    "    \n",
    "convert_to_coco_format('test')\n",
    "convert_to_coco_format('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
